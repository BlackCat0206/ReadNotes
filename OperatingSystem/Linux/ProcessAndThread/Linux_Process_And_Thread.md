# Linux_Process_And_Thread

---- Chime Lee

## 一、概述

Linux下进程与线程的相关概念与日常问题

## 二、内容

### 2.1 什么是进程？什么是线程？有什么区别？

**进程（Process）：**

* 是系统**资源分配的最小单位**。
* 进程是线程的容器。程序是指令、数据及其组织形式的描述，**进程是程序的实体**。

**线程（Thread）：**

* 操作系统**最小的调度单位**。
* 线程包含在进程中，是进程中实际执行任务的单位。

**进程和线程的区别：**

* 所属关系：
  * 线程是进程的一部分，是进程中执行任务的单位。
  * 而进程是操作系统资源分配的基本单位。
* 系统资源：
  * 每个进程都有独立的**地址空间**和**系统资源**。
  * 线程**共享同一进程**的地址空间和资源资源。
* 切换速度：线程之间的切换速度 > 进程之间的切换速度，因为**线程共享相同的上下文和资源**。
* 通信方式：
  * 线程因天然共享同一进程的地址空间，可之间**读写全局变量、堆内存等共享区域**。通信更加方便。
  * 进程拥有独立的地址空间，即便可以使用共享内存，也许通过**内核创建、挂载内存段并处理跨进程同步**，其余通讯协议间通信协议（管道、消息队列、信号量、套接字）则需要而外**内核态数据拷贝**或**协议封装**。
* 开销：进程创建和销毁比线程的开销更大。
* 独立性：
  * 进程是**相对独立**的，一个进程的崩溃不会影响其他进程。
  * 线程是**相互依赖**的，一个线程的崩溃会导致整个进程的崩溃。

### 2.2 什么时候用进程，什么时候用线程？

**使用进程的情况：**

* **需要独立的地址和系统资源**：任务需要运行在独立的空间中，不同任务之间的**数据隔离**较为重要，那么可以选择使用进程。
* **需要更高的安全性和稳定性**：如果一个任务崩溃不影响其他任务的正常运行，选择进程保证安全性和稳定。
* **并行计算需求**：如果任务需要充分利用**多核处理器的计算能力**，可以通过多个独立的进程并行执行提高计算效率。

**使用线程的情况：**

* **共享数据和资源**：若任务之间需要**共享数据和资源**，并且**数据同步和通讯**较为频繁，使用线程可以更方便地访问和操作共享资源。
* **轻量级任务：**如果任务比较轻量级，且**并行**执行可以提高效率，使用线程可以进行更快速地**切换和调度**，减少开销。
* **实时性要求：**如果任务实时性要求比较高，使用线程可以**更快响应事件和处理任务**。

### 2.3 一个线程占多大内存

一个线程在Linux系统中大约占用8 MB的内存。

原因：Linux系统中的线程都是通过**缺页异常**来进行内存分配的，**不是所有的栈空间都会被实际分配内存**。因此，8 MB是一个上限，**实际的内存消耗会超过实际需要的内存**。这个差额主要是由**内部损耗**（每个线程内部一些开销）所引起的，通常在4 KB范围内。

### 2.4 什么是信号量，有什么作用？

* 信号量：一种同步机制，它本质上是一个计数器。
* 作用：保护共享资源，控制访问共享资源的进行或线程数量。
* 原理：基于P和V两种操作：
  * P：操作会将信号量的值-1。若信号量的值小于0，进程或线程会被挂起，直到其他进程或线程执行V操作释放信号量。
  * V：操作会将信号量的值+1。若有进程或线程因等待信号量被挂起，它们中的一个会被唤醒继续执行。
* 信号量的值：
  * 大于0：进程或线程可以继续访问 共享资源。
  * 等于0：进程或线程会被挂起，直到其他进程或线程执行V操作释放信号量。

```cpp
#include <iostream>
#include <semaphore>
#include <thread>

std::counting_semaphore<1> semaphore; // 创建一个信号量，初始值为 1
int counter = 0; // 共享资源

void IncrementCounter() {
    semaphore.acquire(); // P(sv) 操作

    // 访问共享资源
    counter++;
    std::cout << "Counter: " << counter << std::endl;

    semaphore.release(); // V(sv) 操作
}

int main() {
    constexpr int NumThreads = 3;
    std::vector<std::thread> threads;

    // 创建多个线程并启动
    for (int i = 0; i < NumThreads; i++) {
        threads.push_back(std::thread(IncrementCounter));
    }

    // 等待所有线程完成
    for (auto& thread : threads) {
        thread.join();
    }

    return 0;
}
```

### 2.5 多进程共享内存可能存在什么问题？如何解决？

**多进程共享内存可能存在以下问题：**

* 竞争条件（*Race Condition*）：当多个进程同时访问修改共享内存时，由于**执行顺序的不确定性**，导致**数据不一致**或**不正确**的结果。
* 数据同步问题：不同进程可能以**不同速度访问共享内存**，导致**数据在读取和更新之间**的差异，导致**数据不一致**的情况。
* 死锁：多个进程在访问共享内存时发生**互相等待**的情况，可能发生死锁，导致进程无法执行。

**解决措施：**

* 使用互斥锁（*Mutex*）：在访问前获取互斥锁，在访问后释放，保证同一时间只有一个进程访问共享内存。避免**竞争条件**。
* 使用信号量（*Semaphore*）：使用信号量来同步进程的访问，可以控制同时访问共享内存的数量，从而避免数据同步、和死锁。
* 使用条件变量（*Condition value*）：在满足特点条件下唤醒等待的进程，从而避免等待和资源消耗。
* 使用进程加通讯机制（*IPC*）：管道、消息队列、信号量、套接字等。

### 2.6 多进程、多线程的优缺点

**多进程的优点：**

* 独立地址空间和系统资源：进程有独立的地址空间和系统资源，可以有效的**隔离和保护数据**
* 安全性和稳定性：进程间**相对独立**，一个进程的崩溃不会影响其他进程的正常执行。
* 可扩展性：可以更容易在多个机器上部署，实现**分布式计算**，提高系统的处理能力和吞吐量。

**多进程的缺点：**

* 开销：**创建和管理**进程开销较大，包括**内存和资源**的分配，**上下文切换**等。
* 通讯复杂：进程间通信需要使用特定的*IPC*机制，编写和维护较为复杂。

**多线程的优点：**

* 资源共享：若多个任务之间需要访问共享资源，且数据的同步和通信较为频繁，选择多线程可以更方便的访问共享数据。
* 轻量化：若任务是轻量化的，且并发可以提高效率，选择**多线程更方便的切换和调度**。
* 实时性：若任务实时性强，选择多线程更**快响应任务或处理事件**。

**多线程的缺点：**

* 安全性问题：多线程共享数据是需要考虑**同步和锁机制**，避免**数据竞争**导致不一致的结果。
* 内存占用：每个线程都需**独立的栈空间**和**线程数据结构**，增加**内存消耗**。
* 上下文切换开销：线程切换需要**保持和恢复上下文**，增加**系统开销**。

### 2.7 多进程、多线程同步（通信）方式

**多进程：**

* 互斥锁
* 信号量
* 管道
* 共享内存

**多线程：**

* 互斥锁
* 信号量
* 读写锁

### 2.8 什么是线程同步和互斥

**线程同步：**通过一定的机制，确保多个线程按照一定顺序或规则访问共享资源，避免出现并发导致的竞争条件，数据同步等问题。

**线程互斥**：保护共享资源的机制，确保同一时间只有一个线程可以访问该资源，避免出现竞争条件和数据同步等问题。通过使用互斥锁，只有获取到锁才能进入临界区，其他线程需要等待锁释放。

### 2.9 线程同步与阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？

**线程同步**：通过一定的机制，确保多个线程按照一定顺序或规则访问共享资源，避免出现竞争条件或数据同步等问题。

**线程阻塞**：遇到某些条件而无法继续执行时，暂时挂起线程的状态，等待条件满足再次被执行。

**同步在某些机制下会导致阻塞**：互斥锁场景中，当一个尝试获取已经被其他线程占用的锁时，它会被阻塞，等待锁的释放。直到获取到锁之后，线程继续执行。

**阻塞也不一定意味着同步**：线程阻塞是由于**等待特定条件的满足**或是在**某些操作无法完成之前无法执行**。而同步是为了协调线程之间的顺序和行为。阻塞有时可能和同步有段，但阻塞本事并不代表同步。

同步可能导致线程阻塞，但阻塞不一定与同步相关，它可能是由于其他因素引起的。

### 2.10 并发、同步、异步、互斥、阻塞、非阻塞的理解

* 并发：多个任务或操作在同一时间段内执行，它们彼此独立，不一定**按照严格的顺序**执行。
* 同步：协调多个任务或操作之间的顺序和行为，以确保数据的一致性。
* 异步：任务或操作可以独立于当前线程继续执行，不需要等待其他任务完成。
* 互斥：通过一种机制确保同一时刻只能有一个任务或线程访问共享资源。它通过锁或信号量等机制实现，避免竞争条件、数据同步等问题。
* 阻塞：一个线程或任务在执行过程遇到某种条件而无法继续执行时，暂停执行，等待条件满足后被唤醒。
* 非阻塞：当前任务或在执行过程中不会暂停等待条件满足，而是**立即返回**并**继续执行其他任务**。

### 2.11 父进程、子进程的关系以及区别

**父进程**：创建子进程的进程。父进程在创建子进程时，会为其分配**独立资源**和**运行环境**。

**子进程**：父进程创建的新禁止。子进程会继承**父进程的大部分属性和资源**。它可以独立运行，且可以执行不同的**代码路径**。子进程可以创建自己的子进程，形成进程的层次结构。

**父进程和子进程之间有以下几个区别**：

* 进程ID：每个进程在系统中都有一个唯一的ID。父进程在创建子进程时，会将其进程ID分配给它。
* 进程关系：父进程和子进程建立了一种层次关系，父进程是子进程的创造者和管理者。
* 资源继承：子进程会继承父进程的大部分属性和资源，包括**打开的文件**、**环境变量**和**当前工作的目录**。
* 进程通信：父进程和子进程可以通过**进程间的通信机制**来进行**交互和数据共享**，管道、消息队列、共享内存等。
* 生命周期：父进程和子进程的生命周期是**相互独立**的。子进程可以在父进程推出后继续存在，成为**孤儿进程**，由**系统init进程**接管管理。

### 2.12 正确处理僵尸进程的办法

* 在`frok()`创建子进程后，应即使调用`wait()`或`waitpid()`系统调用来**回收子进程的资源**。

同时可以通过**注册SIGCHID信号处理函数**，在函数内部调用`wait()`或`waitpid()`处理子进程的终止状态，避免**僵尸进程**的积累。

* `kill`命令，向进程发送信号。如果父进程在子进程退出后没有处理SIGCHID信号，可以使用kill命令发送SIGCHID信号给父进程，触发父进程处理僵尸进程。

```base
# 找到僵尸进程PID
ps aux | grep Z
# 使用kill命令向父进程发送SIGCHID信号强制杀死父进程
kill -s SIGCHID <parent_pid>
```

* 这样父进程就会**收到SIGCHID信号**或**被强制杀死**，并由父进程（通常是init进程）接管僵尸进程的处理操作。

### 2.13 一个进程可以创建多少个线程，和什么有关？

理论上，32位Linux系统下一个进程可用的用户态地址空间是3G（虚拟内存地址一共是4G，1G给内核），默认一个线程的栈空间是8M，所有理论上一个进程可以创建3G/8M = 380个线程	

### 2.14 什么是进程上下文、中断上下文？

**进程上下文（*Process Context*）:**

* 进程上下文是指**操作系统**在**执行进程**时所需的**所有状态的集合**。
* 代码、数据、进程标识符、堆栈、寄存器的值等。

**使用场景：**

* 当操作系统需要**切换正在执行的进程**，将CPU的资源分配给其他进程时，会发生进程的上下文切换。
* 当**进程阻塞**等待某个事件发生时，进程的上下文会被保存，因此时进程无法继续执行。

**中断上下文（*Interrupt Context*）**：

* 中断上下文是指当发生**中断**或**异常**时，**硬件**或**操作系统内核**自动保存当前**被中断程序的执行现场**，并切换到**中断处理程序执行的上下文**。
* 中断上下文包含：**寄存器状态**、**堆栈指针**、**中断原因**等信息。

**使用场景：**

* 当**硬件设备**发生某种事件，如I/O完成、定时器中断等，会触发中断，**切换到中断上下文，执行中断处理程序**。
* 在中断处理程序执行过程中，**保存和恢复被中断程序的上下文是必要的**，**以确保被中断的程序在中断处理完成后，能够恢复执行并正确继续运行**。

### 2.15 如何创建守护进程

* **创建子进程**：父进程中调用`fork()`函数创建子进程
* **终止父进程**：父进程调用`exit()`函数，使子进程成为孤儿进程。
* **调用`setsid()`创建新会话**：子进程会调用`setsid()`创建一个新的会话。这将会使子进程成为**会话领导者**，并且与**父进程和控制终端解除关系**。
* **更改当前目录位根目录**：守护进程通常将工作目录位根目录，避免后续操作和其他**进程目录关联**。
* **重设文件权限掩码**：守护进程调用`umask()`函数来**重设文件掩码**，这样就可以确保**守护进程创建的文件有适当的权限**。
* **关键文件描述符**：守护进程会关闭不再需要的**文件描述符**，（stdin/stdout/stderr），防止守护进程意外地和**操作终端**产生交互。

### 2.16 孤儿进程、僵尸进程、守护进程的概念

孤儿进程：父进程先于子进程结束，子进程成为孤儿进程并由`init`进程接管。

僵尸进程：子进程已经终止，但父进程尚未调用`wait()`或`waitpit()`来获取子进程的终止状态，子进程进入僵尸状态。

守护进程：在后台运行的特殊进程，通常以**init进程为父进程**，独立于终端或控制终端，用于**执行常驻任务**。

### 2.17 进程有哪五种状态，如何转换？

**Linux进程有五种核心状态：**

运行态（R），可中断休眠态（S）、不可中断休眠态（D）、僵尸态（Z）、终止态（X）。

**状态转换核心逻辑：**

* 进程创建后进入**就绪（归为R）**，**调度器**分配CPU后转为**运行态（R）**；运行态进程时间片耗尽就会回到就绪，抢占CPU时间片。
* 运行态（R）进程等待**磁盘/网络/键盘**这类普通资源时，进入**可中断休眠态（S）**，资源就绪或收到信号就能**唤醒回到就绪**。等待磁盘IO这类核心资源时，进入**不可中断休眠态（D）**，只能等待资源完成才能唤醒，不受信号打断，防止数据损坏。
* 运行态执行完毕或被信号终止，会进入**僵尸态（Z）**，此时进程释放大部分资源，仅保留PCB等待父进程回收。父进程回收后进入**终止态（X）**，进程彻底消亡。

### 2.18 死锁的原因、条件？如何预防？

**死锁：**进程或现场访问共享资源时，因争夺**彼此持有但无法被剥夺的资源**产生了相互等待，此时系统产生了死锁。

**产生的条件：**

* **互斥锁**：同一时间只能有一个进程或现场访问共享资源 ，其余进程或线程阻塞等待。
* **请求与保持条件**：线程或进程已持有分配的资源，同时再次申请资源，申请失败后，**不释放已持有资源**。
* **不剥夺条件**：线程或进程已持有资源，只能**自己主动释放**，无法被其他线程或进程**剥夺**。
* **循环等待条件**：线程或进程间形成了**循环等待链**，每个进程或线程都持有下一个进程等待的资源，同时等待上一个进程或线程持有的资源。（如：A线程有锁1等锁2，B线程有锁2等锁1）。

**处理死锁的策略**：按优先级

* **预防死锁**：核心思路，破坏产生死锁的四个原因之一。从根源解决问题，实现简单，适合嵌入式场景。

  * **循环等待条件：**对共享资源编号，所有线程/进程必须严格按照顺序【从小到大】申请，【从大到小】释放。

  * 嵌入式场景举例（多线程操作双互斥锁）：

    定义两把互斥锁：

    ```
    pthread_mutex_t mutex1; // 编号1
    ```

    ```
    pthread_mutex_t mutex2; // 编号2
    ```

    - 线程 A（需要 mutex1+mutex2）：先`pthread_mutex_lock(&mutex1)` → 再`pthread_mutex_lock(&mutex2)` → 执行临界区操作 → 依次解锁`mutex2`、`mutex1`。
    - 线程 B（需要 mutex2+mutex1）：遵循同样顺序，先`pthread_mutex_lock(&mutex1)` → 再`pthread_mutex_lock(&mutex2)` → 执行临界区操作 → 依次解锁`mutex2`、`mutex1`。

  * **请求与保持条件**：**”一次性申请所有需要的资源“**，若有一个申请失败，则释放所有已申请的资源，等待后重新申请，注意这里要添加**随机/递增的延迟**，避免活锁问题。

  * **破坏不可剥夺条件：**线程/进程申请超时后，主动释放已占有资源，避免永久阻塞。

* **避免死锁**：核心思路“**动态检测系统资源分配是否安全**”，在每次分配前通过算法（银行家算法）检测分配后系统是否会进入不安全状态。适合大型操作系统，嵌入式中极少用。

* **检测死锁**：定时扫描**线程/进程的资源持有与申请状态**，判断是否出现**循环等待链**，若出现发出告警。无提前干预，仅作记录。

* **解除死锁**：检测到死锁后，通过强制剥夺资源，杀死死锁线程，重启进程的方式接触死锁；会导致数据丢失，功能异常。嵌入式中绝对禁止使用。

### 2.19 活锁的原因？与解决方案

**活锁**：多进程/线程为了解决资源竞争的问题，**主动释放已持有的资源并反复尝试重新申请**，导致所有线程/进程处于“**释放-申请-再释放**”的循环中，陷入无效工作。

**形成原因：**

* **线程申请资源失败后，无延迟的立刻重新申请**：为了解决死锁“保持与请求条件”时的处理不当实现。
* **线程间的“谦让逻辑”高度同步，导致无效避让**。
  * 线程A和B同时申请锁1，A成功，B失败。
  * 线程A申请锁2，发现锁2被B占有，A释放资源后立刻重试。
  * 线程B因为申请锁1失败，释放了锁2，立刻重试。
  * 两者的谦让模式完全相同，但始终无法同时获取锁1 和 锁2。
* **资源分配的“饥饿”问题**：高优先级线程频繁抢占资源，低优先级线程只能反复释放-重复申请，长期无法获得资源，也会变为活锁。

**解决方案：**

* **解决死锁的“循环等待条件”：**所有资源进行编号，要求所有线程与进程按照顺序进行申请和释放。
* **解决死锁的“保持和请求条件”：**申请资源后，添加随机/递增的延迟再重试。
* **设计差异化的谦让/重试逻辑，避免线程行为同步**：
  * 高优先级延迟短，低优先级延迟长。
* **限制重试次数，避免无限循环**：

### 2.20 死锁和活锁的区别

| 对比维度     | 死锁                         | 活锁                               |
| ------------ | ---------------------------- | ---------------------------------- |
| 线程状态     | 永久阻塞                     | 活跃运动状态                       |
| 资源持有情况 | 各线程持有部分，但不主动释放 | 各线程不主动持有，并主动已持有释放 |
| 循环特性     | 闭环等待，无任何操作推进     | 无效循环，有操作但核心任务无推进   |
| 直观表现     | 系统“卡死”，无任何响应       | 系统“忙碌”，但核心业务无进展       |

### 2.21 `epoll`和`select`的区别？为什么`epoll`更高效

**区别：**

* **监听的`fd`数量限制：**
  * `select`：有最大数量限制，1024，内核编译时常量，无法修改。
  * `epoll`：没有硬限制，能监听的`fd`的数量与系统的内存有关，轻松支持几万，十几万并发连接。
* **内核态与用户态的拷贝开销：**
  * `select`：每次调用`select`，都要把用户态的`fd`集合**拷贝到内核态**，内核处理完成后，又把就绪的`fd`集合拷贝回用户态，每次调用都要**双向拷贝**，`fd`越多，拷贝开销越大。
  * `epoll`：仅再调用`epoll_ctl`添加/删除/修改监听`fd`，做**一次数据拷贝**，后续调用`epoll_wait`获取事件，完全不需要拷贝`fd`集合，只有少量内核句柄传递，**几乎无拷贝开销**。
* **就绪事件查询效率：**
  * `select`：内核只返回有“有事件就绪”，并不会具体说明是那些`fd`，用户从要**遍历所有监听的`fd`**，事件复杂度O(n)，`fd`数量越多，耗时越久，性能越差。
  * `epoll`：内核维护了一个**就绪用户队列**，为每个fd绑定了一个回调函数，`fd`就绪时，内核通过回调将其添加至就绪队列。`epoll_wait`直接获取到就绪`fd`，用户层直接处理即可，时间复杂度O(1)，无论监听的fd数量多少，效率不变。

* **`fd`的维护方式**：
  * `select`：每次调用前，需要**重新初始化并设置`fd`集合**，因为`select`调用后会修改原有`fd`集合，清空未就绪的`fd`，编程繁琐且有而外开销。
  * `epoll`：注册到`epoll`中的`fd`会被**内核长期维护**，无需重复设置，需要修改监听事件时，通过`epoll_ctl`修改即可。

`epoll`高效的原因：

* 无`fd`数量的限制，极少的内存拷贝开销，**事件驱动O(1)查询效率**，无需重复设置`fd`集合。

`epoll`两者工作模式：水平触发（LT）默认，和边缘触发`ET`

* LT：fd只要处于就绪态，每次调用`epoll_wait`就会返回该事件，直到事件被处理。
* ET：仅在`fd`的状态**由未就绪变为就绪那一刻**，才会触发一次通知，效率更高，但编程要求更严各，需要一次性把fd就绪数处结束，否则会丢失事件。
